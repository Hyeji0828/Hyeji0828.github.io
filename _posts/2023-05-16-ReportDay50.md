---
layout: posts
title: "[Day50] 5월16일 일일리포트"
date: 2023-05-16
category: AITech5
---

## 강의 복습

## 멘토링

**대회 관련**

- nms, soft nms, weighted box fusion을 사용해보고 결과가 어떻게 바뀌는지 확인해보는 것도 좋은 목표일 것
- 옛날에는 작은 모델에서 실험하고 insight를 얻어 큰 모델로 확장했지만, 이제는 모델이 다 커지고 작은 모델이 성능에서 따라갈 수 없어졌다. 대회에서 성능을 높이는 방법은 깊은 생각없이 이것저것 실험을 해보는 게 요즘 트렌드인 듯하다.
- Detection에서는 정성/정량 평가가 일치하지 않는 경향이 크다. metric의 문제점. 그래서 정성적 평가(봤을 때 잘 측정하는 것 같다 싶은)가 잘 나오는 것도 괜찮다.
- Detection 분야는 MMDetection에 의존적이라 custom backbone, neck, head를 시도해보는 것이 도움이 될 수 있다.
- f16 → 시간적인 효율성을 높일 수 있지만 메모리 공간적으로 효율성을 얻지는 못 할것. (하드웨어에 의존적이라)
- batch normalization → n이 30이상일 때 정규화 가능 = batch가 32, 64, 최소 16이 되어야 효과가 있다. 그 이하는 drop out이 낫다. 이런 문제를 보완하는게 layer normalization.
- 레이어가 많아졌는데 성능이 올라가지 않았다?
    
    → 데이터가 생각보다 복잡하지 않았던 것일 수 있다. 
    
- mosaic은 성능이 올랐는데 mixup은 떨어졌다?
    
    → 데이터에 의존적이다. 데이터가 어떤지에 따라서 data augmentation이 효과가 있을 수도 없을 수도 있다. mosaic 하기 전 crop 단계에서 bbox가 짤리지 않도록 하는 것을 신경쓰자. mmdetection utils에 browse dataset으로 실제 눈으로 확인해보는 것 추천.
    
- 1-stage 모델은 yolo를 대부분 사용하고 version 3,7,8 추천.
- wrap-up 리포트는 실험에 대해서만 적어두면 피드백도 도움이 안된다. 어떤 모델을 선택했고 어떤 결과가 나왔고 그에 대한 내 생각은 어땠는지 식으로 작성할 것.

---

**Universal Approximation Theorm (만능 근사 정리)**

- 적당한 수의 뉴런을 갖는, sigmoid 함수를 사용하는, 1층짜리 신경망은 모든 함수를 근사할 수 있다.
1. weight가 무한에 가깝게 커지면 sigmoid는 계단 모양의 step function이 된다.
2. $f = \sum{C_k \sigma(\sum W_{ik}x_i + b_k)}$ 로 bump function을 근사할 수 있다.

딥러닝을 근사할 수 있는 최소한의 정리 ⇒ 왜 최소한인가? 문제는 무엇인가?

## 피어세션

- 진행 상황 및 앙상블 계획 공유
    - 각자 모델들을 앙상블한 결과를 모아서 다시 앙상블

## 학습 회고

yolov3, yolov8, ssd 세 가지 모델을 돌리는데 대부분의 시간을 써서 아쉽지만 mmdetection과 ultralytics의 사용법을 알게된 것으로 만족한다. 남은 시간 동안은 최대한 실험을 많이 해보고 앙상블을 적용하는 것이 목표다.

## Done List

- [x]  yolov8 pretrained 모델 x 버전 학습
- [x]  Focal loss 세팅 (yolov3 / ssd)
- Multi scale 실험
    - [x]  yolov8 → 지원 X
    - [x]  yolov3
    - [x]  ssd
- [x]  yolov3 soft nms 실험

---
